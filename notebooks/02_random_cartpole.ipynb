{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Random CartPole\n",
    "\n",
    "\n",
    " - **About**: Buildling a random agent for controling CartPole environment\n",
    " - **Gym link**: https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gym intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miro/virtualenvs/deep-rl-hands-on/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "e = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03626936, -0.04434125, -0.0498571 ,  0.02695358])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the environment and return initial state\n",
    "obs = e.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List actions (2 discrete states, 0-left, 1-right)\n",
    "e.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(4,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List state/observation space (Observation returns 4 continuous states)\n",
    "\"\"\"\n",
    "Observation: \n",
    "        Type: Box(4)\n",
    "        Num Observation                 Min         Max\n",
    "        0   Cart Position             -4.8            4.8\n",
    "        1   Cart Velocity             -Inf            Inf\n",
    "        2   Pole Angle                 -24°           24°\n",
    "        3   Pole Velocity At Tip      -Inf            Inf\n",
    "\"\"\"\n",
    "e.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.03538253, -0.23871407, -0.04931803,  0.30349861]), 1.0, False, {})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move in environment to left\n",
    "e.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get action sample\n",
    "e.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.0658181e+00,  6.9937125e+37,  3.7601247e-02, -5.1957849e+37],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get sate/observation sample\n",
    "e.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buliding random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode done in 1 steps, total reward 1.00\r",
      "Episode done in 2 steps, total reward 2.00\r",
      "Episode done in 3 steps, total reward 3.00\r",
      "Episode done in 4 steps, total reward 4.00\r",
      "Episode done in 5 steps, total reward 5.00\r",
      "Episode done in 6 steps, total reward 6.00\r",
      "Episode done in 7 steps, total reward 7.00\r",
      "Episode done in 8 steps, total reward 8.00\r",
      "Episode done in 9 steps, total reward 9.00\r",
      "Episode done in 10 steps, total reward 10.00\r",
      "Episode done in 11 steps, total reward 11.00\r",
      "Episode done in 12 steps, total reward 12.00\r",
      "Episode done in 13 steps, total reward 13.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miro/virtualenvs/deep-rl-hands-on/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "total_reward = 0.0\n",
    "total_steps = 0\n",
    "obs = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    total_steps += 1\n",
    "    if done:\n",
    "        break\n",
    "    print(\"\\rEpisode done in %d steps, total reward %.2f\" % (total_steps, total_reward), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor  (random agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miro/virtualenvs/deep-rl-hands-on/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode done in 10 steps, total reward 10.00"
     ]
    }
   ],
   "source": [
    "# Adding monitor\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.wrappers.Monitor(env, 'recording')\n",
    "total_reward = 0.0\n",
    "total_steps = 0\n",
    "obs = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    total_steps += 1\n",
    "    if done:\n",
    "        break\n",
    "    print(\"\\rEpisode done in %d steps, total reward %.2f\" % (total_steps, total_reward), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls src=\"img/openaigym.video.0.39871.video000000.mp4\" width=\"320\" height=\"240\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-rl-hands-on",
   "language": "python",
   "name": "deep-rl-hands-on"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
